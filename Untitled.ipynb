{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class PennFudanDataset(object):\n",
    "    def __init__(self, root, transforms):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        # 下载所有图像文件，为其排序\n",
    "        # 确保它们对齐,而且这样就把图片名字列出来了，方便了加载图片\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"PNGImages\"))))\n",
    "        self.masks = list(sorted(os.listdir(os.path.join(root, \"PedMasks\"))))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images ad masks\n",
    "        img_path = os.path.join(self.root, \"PNGImages\", self.imgs[idx])\n",
    "        mask_path = os.path.join(self.root, \"PedMasks\", self.masks[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        # 请注意我们还没有将mask转换为RGB,\n",
    "        # 因为每种颜色对应一个不同的实例\n",
    "        # 0是背景\n",
    "        mask = Image.open(mask_path)\n",
    "        # 将PIL图像转换为numpy数组\n",
    "        mask = np.array(mask)\n",
    "        # 实例被编码为不同的颜色\n",
    "        obj_ids = np.unique(mask)\n",
    "        # 第一个id是背景(即0)，所以删除它\n",
    "        obj_ids = obj_ids[1:]\n",
    "\n",
    "        # 将相同颜色编码的mask分成一组 这样可能更好理解：masks = (mask == obj_ids[:, None, None])\n",
    "        # mask为2维，用None扩充obj_ids维度，masks为3维\n",
    "        # 二进制格式\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "\n",
    "        # 获取每个mask的边界框坐标\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            # masks[i]为2维，所以np.where返回2个tuple，分别为此颜色编码的元素在各个维度的下标\n",
    "            # 这里的数据中不同颜色的mask应该是语义分割的像素点，选出最大最小的x坐标和y坐标就得到了目标区域,因为这里我们做的目标检测，所以需要这个信息\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        # 将所有转换为torch.Tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # 这里仅有一个类(行人，所以直接全部置为1)\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # 假设所有实例都不是人群\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes  # 这张图片里所有的目标区域\n",
    "        target[\"labels\"] = labels   # 每个目标区域的类型\n",
    "        target[\"masks\"] = masks    # 图像掩膜 mask\n",
    "        target[\"image_id\"] = image_id  # 图片id\n",
    "        target[\"area\"] = area          # 每个区域的面积\n",
    "        target[\"iscrowd\"] = iscrowd    # 每个区域是否是人群(这里假设的都不是)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理完了麻烦的数据，我们终于可以定义模型了，这里我们使用mask R-CNN， 这是 Faster R-CNN的升级版。也是detectron使用的目标检测算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
